{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decaptcha Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import glob\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import imutils\n",
    "#CV2 is the module of openCV for python, this module will deal with graphics such as images and videos.\n",
    "#In this file, it is used together with imutils to process and read the dataset which are all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os is used to set the working directory in order to access the dataset\n",
    "import os\n",
    "os.chdir('D:\\Samples\\samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = glob.glob(\"enter_folder_or_path_here\") #storing the location of all the images in variable path\n",
    "outpath = (\"enter_folder_orpath_here\")\n",
    "#imgs = [] #creating an empty list\n",
    "\n",
    "image_no = 1\n",
    "for img in path: #running a loop to iterate through every image in the file\n",
    "    pic = cv2.imread(img) #reading the image using matplotlib\n",
    "    gray_pic = cv2.cvtColor(pic, cv2.COLOR_BGR2GRAY) #converting the image into grayscale\n",
    "    r, threshold = cv2.threshold(gray_pic, 110, 255, cv2.THRESH_OTSU) #converting the image into grayscale using the histogram method\n",
    "    \n",
    "    # need add de-noise element from exploration python file.\n",
    "    \n",
    "\n",
    "    ## This will write out code to a new folder on the local host - may need remove\n",
    "    cv2.imwrite(outpath + str(image_no) + '.jpg', threshold) # write to the test_pImg folder \n",
    "    image_no +=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imread reads images from a graphic file\n",
    "img = cv2.imread(\"3den6.png\", 0)\n",
    "\n",
    "#imshow displays the data, numpy array, as an image\n",
    "plt.imshow(img, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adaptive thresholding - this method calculates the threshold value for smaller regions.\n",
    "#This will be for images that does not have constant lighting values\n",
    "th = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 17, 2)\n",
    "\n",
    "#otsu thresholding - this thresholding method automatically assigns a value compared to global thresholding\n",
    "#which needs an assigned constant value\n",
    "ret2, th2 = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "#otsu thresholding with gaussian blur - this method is just like the otsu but with gaussian blurring to\n",
    "#smoothen the image by blurring the image. By blurring the image, the edges become smoother\n",
    "blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "titles = ['Original', 'Adaptive', 'Otsu', 'Gaussian + Otsu']\n",
    "images = [img, th, th2, th3]\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing noise - in this case the line in the image\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "dilation = cv2.dilate(th, kernel, iterations = 1)\n",
    "dilation2 = cv2.dilate(th2, kernel, iterations = 1)\n",
    "dilation3 = cv2.dilate(th3, kernel, iterations = 1)\n",
    "\n",
    "titles2 = ['Original', 'Adaptive', 'Otsu', 'Gaussian + Otsu']\n",
    "images2 = [img, dilation, dilation2, dilation3]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1), plt.imshow(images2[i], 'gray')\n",
    "    plt.title(titles[2])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Erosion is used to remove the pixels on the object's boundary\n",
    "erosion = cv2.erode(dilation, kernel, iterations = 1)\n",
    "erosion2 = cv2.erode(dilation2, kernel, iterations = 1)\n",
    "erosion3 = cv2.erode(dilation3, kernel, iterations = 1)\n",
    "\n",
    "titles3 = ['Original', 'Adaptive', 'Otsu', 'Gaussian + Otsu']\n",
    "images3 = [img, erosion, erosion2, erosion3]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1), plt.imshow(images3[i], 'gray')\n",
    "    plt.title(titles3[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further remove noise after the erosion\n",
    "kernel = np.ones((3,1), np.uint8)\n",
    "dilation2_1 = cv2.dilate(erosion, kernel, iterations=1)\n",
    "dilation2_2 = cv2.dilate(erosion2, kernel, iterations=1)\n",
    "dilation2_3 = cv2.dilate(erosion3, kernel, iterations=1)\n",
    "\n",
    "titles4 = ['Original', 'Adaptive', 'Otsu', 'Gaussian + Otsu']\n",
    "images4 = [img, dilation, dilation2, dilation3]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1), plt.imshow(images4[i], 'gray')\n",
    "    plt.title(titles4[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bounds each character inside a box for post-segmentation\n",
    "x, y, w, h = 31, 13, 21, 39\n",
    "for i in range(5):\n",
    "    cv2.rectangle(img, (x,y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    cv2.rectangle(dilation, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    cv2.rectangle(dilation2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    cv2.rectangle(dilation3, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    x += w\n",
    "    \n",
    "titles5 = ['Original', 'Adaptive', 'Otsu', 'Gaussian + Otsu']\n",
    "images5 = [img, dilation, dilation2, dilation3]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1), plt.imshow(images5[i], 'gray')\n",
    "    plt.title(titles5[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
